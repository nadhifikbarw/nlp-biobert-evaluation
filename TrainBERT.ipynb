{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5b72db9-73e3-4379-9e4e-05b2ab5e461f",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08b2663-20e0-4fef-810c-171af6ab188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset for training\n",
    "import pandas as pd\n",
    "tag_df = pd.read_csv('dataset/tagging_classification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40b2191-0c79-4bfc-a8af-bb79f43e2b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: requests in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (4.49.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\reactive\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sacremoses->transformers) (8.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->sacremoses->transformers) (0.4.4)\n",
      "Requirement already satisfied: datasets in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: pyarrow<4.0.0,>=1.0.0 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.12.2)\n",
      "Requirement already satisfied: dill in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: fsspec in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2021.6.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub<0.1.0 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.0.12)\n",
      "Requirement already satisfied: pandas in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.2.4)\n",
      "Requirement already satisfied: tqdm<4.50.0,>=4.27 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.49.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\reactive\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\reactive\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "# Download HuggingFace's transformers and datasets library\n",
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17fbf0a5-97b0-4d10-aa34-c6bb9e4b53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode tag/Label to make it compatible with BERT\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode Label\n",
    "label_encoder = LabelEncoder()\n",
    "tag_df['label'] = label_encoder.fit_transform(tag_df['Tag'])\n",
    "num_labels=len(label_encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d7a9cda-c719-4e84-adca-dcb9f0d5b796",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/config.json from cache at C:\\Users\\Reactive/.cache\\huggingface\\transformers\\78e6e8ece5b58501028ce314273009ad7707ef4c5ba44251914fd6bca8a05eff.e4a2e693122d98b8b56b7dc1f0d89b644226aacef228afb5030ee3621b2829d3\n",
      "Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/vocab.txt from cache at C:\\Users\\Reactive/.cache\\huggingface\\transformers\\cda9c238619f77c4dbf65f23ab841b5239f0289800d673957c843b9dda52ad44.437aa611e89f6fc6675a049d2b5545390adbc617e7d655286421c191d2be2791\n",
      "loading file https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/dmis-lab/biobert-base-cased-v1.1/resolve/main/tokenizer_config.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "# Create tokenizer for tokenization\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a01fe40-6f47-4500-bcbe-37d96156a03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4704d839fcf34435b03c74fc3f9359e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame into HuggingFace's Dataset and perform tokenization\n",
    "from datasets import Dataset\n",
    "raw_datasets = Dataset.from_pandas(tag_df).rename_column('Value', 'text')\n",
    "\n",
    "# Define tokenization callback and perform tokenization\n",
    "def tokenize_function(examples): return tokenizer(examples[\"text\"], max_length=512, padding=\"max_length\", truncation=True)\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e7cb5e2-4cbc-4ddb-b891-1a2527471624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 70:30 split for train and test dataset \n",
    "SPLIT_SEED = 67\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.train_test_split(test_size=.3, seed=SPLIT_SEED)\n",
    "train_dataset = tokenized_datasets['train']\n",
    "eval_dataset = tokenized_datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a1c6c-e0e0-40d2-99bd-32941ca3d155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splitted trainset and testset to be used by other model training\n",
    "train_dataset.to_csv('dataset/tagging_classification_train.csv')\n",
    "eval_dataset.to_csv('dataset/tagging_classification_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4635cf7-c8b1-4305-9f75-ae0d00a3c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BioBERT pre-trained model to fine tune\n",
    "# IGNORE the warning it's expected\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-base-cased-v1.1', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e30808-9e79-48db-86eb-146eea923fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics for each evaluation checkpoint during training\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "def compute_metrics(p):\n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred, average='micro')\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcaf55f-b7ad-48df-843c-10b12d3cabab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Trainer and configure its arguments\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Small batch size because CUDA memory only 4GB (1050TI)\n",
    "BATCH_SIZE=1\n",
    "OUTPUT_PATH='biobert-cased-classification-klikdokter'\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    OUTPUT_PATH,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab8f2ea-219d-4b9e-88c8-03d118e5cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e09b51-8d4b-4878-98bf-d542ba172191",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a3f3a45-d103-4a93-a061-3f3066958aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./biobert-cased-classification-klikdokter/checkpoint-5500\\config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dmis-lab/biobert-base-cased-v1.1\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "loading weights file ./biobert-cased-classification-klikdokter/checkpoint-5500\\pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./biobert-cased-classification-klikdokter/checkpoint-5500.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text, Artikel, Tag.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 807\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='101' max='101' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [101/101 00:55]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained('./biobert-cased-classification-klikdokter/checkpoint-5500', num_labels=num_labels)\n",
    "test_trainer = Trainer(model)\n",
    "raw_pred, _, _ = test_trainer.predict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a79858-cc19-499c-8b41-15c92f83c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted label\n",
    "import numpy as np\n",
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "y_pred_labeled = label_encoder.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "537b536b-6a90-4c74-8073-5c9d2c3169f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual label\n",
    "y_actual = eval_dataset.to_pandas()['label']\n",
    "y_actual_labeled = label_encoder.inverse_transform(y_actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca62fa98-67c0-425f-b1f2-0b4b085a9960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Artikel       0.00      0.00      0.00         2\n",
      "      Gejala       0.40      0.41      0.41        56\n",
      "       Kapan       0.60      0.50      0.55        30\n",
      "       Objek       0.72      0.65      0.68        85\n",
      "   Observasi       0.00      0.00      0.00         6\n",
      "     Outcome       0.46      0.55      0.50        94\n",
      "      Pasien       0.95      1.00      0.97        18\n",
      "     Pembuka       0.72      0.91      0.81        34\n",
      "     Penutup       1.00      0.73      0.85        45\n",
      "    Penyakit       0.56      0.64      0.60        53\n",
      "    Penyebab       0.68      0.57      0.62        76\n",
      "     Periode       0.65      0.71      0.68        21\n",
      "  Pertanyaan       0.80      0.70      0.74        23\n",
      "  Prakondisi       0.16      0.17      0.17        52\n",
      "   Referensi       0.00      0.00      0.00         2\n",
      "    Tindakan       0.73      0.76      0.74       192\n",
      " Usia pasien       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           0.63       807\n",
      "   macro avg       0.56      0.55      0.55       807\n",
      "weighted avg       0.63      0.63      0.63       807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_actual_labeled, y_pred_labeled, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b95a0b-cd88-44ac-af3f-934e249fe240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
