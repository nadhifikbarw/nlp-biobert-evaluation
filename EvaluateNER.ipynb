{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb90103-f38e-4bfd-94f6-90b94f8dfe42",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0bafea0c-f843-4792-88f8-121ae2c06415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def load_ner_data(path):\n",
    "    sentences = []\n",
    "    with open(path, 'r', encoding='utf-8') as fd:\n",
    "        sentence = []\n",
    "        count = 1\n",
    "        for line in fd:\n",
    "            line = line.strip()\n",
    "            if line == '':\n",
    "              if len(sentence) > 0:\n",
    "                sentences.append(sentence)\n",
    "              sentence = []\n",
    "            else: \n",
    "              token_tag = line.split('\\t')\n",
    "              sentence.append(token_tag)\n",
    "            count += 1\n",
    "    return sentences\n",
    "            \n",
    "def load_ner_data_as_df(path):\n",
    "    token_tags = []\n",
    "    with open(path, 'r', encoding='utf-8') as fd:\n",
    "      for line in fd:\n",
    "        line = line.strip()\n",
    "        if line == '':\n",
    "            continue\n",
    "        else:\n",
    "          token_tag = line.split('\\t')\n",
    "          token_tags.append(token_tag)\n",
    "    return pd.DataFrame(token_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bd7c81-44ec-4312-969c-438d89a8eb9b",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "45ecb6f2-5250-4287-89fb-78d834fc7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = load_ner_data_as_df('dataset/NEREnglish.tsv')\n",
    "id_df = load_ner_data_as_df('dataset/NERIndonesia.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8e369a21-9685-414d-a23c-d7dcf83f65ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O             20993\n",
       "B-DISEASE       815\n",
       "I-DISEASE       405\n",
       "B-CHEMICAL      156\n",
       "I-CHEMICAL       54\n",
       "I-GENETIC        27\n",
       "B-GENETIC        20\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_df[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fb48f6e1-6be9-4345-af60-3c0fec6ca0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O             18828\n",
       "B-DISEASE       863\n",
       "I-DISEASE       385\n",
       "B-CHEMICAL      165\n",
       "I-CHEMICAL       51\n",
       "I-GENETIC        23\n",
       "B-GENETIC        22\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_df[1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4415f023-93c6-4c63-9333-502a76b832cc",
   "metadata": {},
   "source": [
    "# NER Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223150f-d0aa-42bb-9e23-adeb539b597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a5c25102-1d73-414d-be84-82e6a4603e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils function source code\n",
    "\n",
    "# Convert tags data and cascade it into sentence\n",
    "# usually for NER input\n",
    "def tokens_to_sentence(tokens):\n",
    "  return \" \".join([token[0] for token in tokens])\n",
    "\n",
    "# Collapse list of entities from NER prediction\n",
    "# and get all the highest scored prediction \n",
    "def collapse_entities(entities_list):\n",
    "  indexs = set()\n",
    "  indexed = []\n",
    "  ret = []\n",
    "  for _ in entities_list:\n",
    "    for e in _:\n",
    "      index = e['index']\n",
    "      indexs.add(index)\n",
    "    indexed.append({e['index'] : e for e in _})\n",
    "  for index in indexs:\n",
    "    entities = [e.get(index, {'score': 0}) for e in indexed]\n",
    "    entities.sort(key=(lambda e: e['score']), reverse=True)\n",
    "    ret.append(entities[0])\n",
    "  return ret\n",
    "\n",
    "# Use to convert tags data for evaluation  \n",
    "# by tokenizing the tagged data using \n",
    "# tokenizer but pass through the label\n",
    "def tokenize_and_preserve_label(tokenizer, tokens):\n",
    "  new_tokens = []\n",
    "  for token in tokens:\n",
    "    old_token = token[0]\n",
    "    label = token[1]\n",
    "    for idx, new_token in enumerate(tokenizer.tokenize(old_token)):\n",
    "      new_label = label\n",
    "      if idx > 0:\n",
    "        if label != 'O':\n",
    "          new_label = 'I' + label[1:]        \n",
    "      new_tokens.append([new_token, new_label])\n",
    "  return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "188ec98a-3208-47bb-9de4-c64129110c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_data_en = load_ner_data('dataset/NEREnglish.tsv')\n",
    "evaluation_data_id = load_ner_data('dataset/NERIndonesia.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7526d17f-3ab1-4909-be30-e694c767be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('alvaroalon2/biobert_chemical_ner')\n",
    "chem_model = AutoModelForTokenClassification.from_pretrained('alvaroalon2/biobert_chemical_ner')\n",
    "gene_model = AutoModelForTokenClassification.from_pretrained('alvaroalon2/biobert_genetic_ner')\n",
    "dise_model = AutoModelForTokenClassification.from_pretrained('alvaroalon2/biobert_diseases_ner')\n",
    "\n",
    "# Create pipelines for all fine-tuned models \n",
    "ner_chem = pipeline('ner', model=chem_model, tokenizer=tokenizer)\n",
    "ner_gene = pipeline('ner', model=gene_model, tokenizer=tokenizer)\n",
    "ner_dise = pipeline('ner', model=dise_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a7cc4101-371d-474a-924d-cb68a6d94d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_predictions(sentences):\n",
    "    # Run predicition for all sentences\n",
    "    predictions = []\n",
    "    for sentence in sentences:\n",
    "      # Tokenize actual tags\n",
    "      actual_entities = tokenize_and_preserve_label(tokenizer, sentence)\n",
    "\n",
    "      # Make predictions\n",
    "      sentence_string = tokens_to_sentence(sentence)\n",
    "      entities = [ner_chem(sentence_string),ner_gene(sentence_string)]\n",
    "\n",
    "      # Handle special case for ner_dise\n",
    "      disease_entities = [e for e in ner_dise(sentence_string) if e['entity'] != '0']\n",
    "      entities.append(disease_entities)\n",
    "\n",
    "      # Join all entities with highest score\n",
    "      predicted_entities = collapse_entities(entities)\n",
    "      # Add O tokens for unpredicted tokens and format it for evaluation\n",
    "      indexed = {e['index']: e for e in predicted_entities}\n",
    "      predicted_entities_all = []\n",
    "      for idx, e in enumerate(actual_entities):\n",
    "        entity = indexed.get(idx+1, None)\n",
    "        entity = [entity['word'], entity['entity']] if entity else [e[0], 'O']\n",
    "        predicted_entities_all.append(entity)\n",
    "\n",
    "      for _ in range(len(actual_entities)):\n",
    "        predictions.append([actual_entities[_][0], actual_entities[_][1], predicted_entities_all[_][1]])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f4442d03-ad00-4fd1-8b81-48704a70457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet slow for large datasets\n",
    "pred_en = pd.DataFrame(perform_predictions(evaluation_data_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ac17a134-25f9-45c4-8ab3-6feefe0d2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quiet slow for large datasets\n",
    "pred_id = pd.DataFrame(perform_predictions(evaluation_data_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc7cd2c0-8980-4d42-b4ea-3b729823cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_en.to_csv('pred_en.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c324d2a8-1919-4d79-bc0c-d19e704cc46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_id.to_csv('pred_id.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d6bb94-836a-4dcb-a98b-07d8dfdb46a0",
   "metadata": {},
   "source": [
    "# Evaluate English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7db788d2-ae99-4522-b13f-1ffa64f609ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-CHEMICAL       0.72      0.92      0.81       156\n",
      "   B-DISEASE       0.65      0.89      0.75       815\n",
      "   B-GENETIC       0.88      0.70      0.78        20\n",
      "  I-CHEMICAL       0.93      0.86      0.90       404\n",
      "   I-DISEASE       0.90      0.73      0.81      1581\n",
      "   I-GENETIC       0.88      0.66      0.75        67\n",
      "           O       0.98      0.98      0.98     23174\n",
      "\n",
      "    accuracy                           0.96     26217\n",
      "   macro avg       0.85      0.82      0.82     26217\n",
      "weighted avg       0.97      0.96      0.96     26217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(pred_en[1],pred_en[2])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce095f94-8485-4c71-8f72-ba5aff911a57",
   "metadata": {},
   "source": [
    "# Evaluate Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ac9d1b6b-042e-4b4f-8af1-59c5d46d6ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  B-CHEMICAL       0.70      0.53      0.61       165\n",
      "   B-DISEASE       0.68      0.10      0.18       863\n",
      "   B-GENETIC       0.46      0.50      0.48        22\n",
      "  I-CHEMICAL       0.92      0.43      0.58       476\n",
      "   I-DISEASE       0.88      0.07      0.13      2582\n",
      "   I-GENETIC       0.36      0.63      0.46        65\n",
      "           O       0.93      1.00      0.96     46146\n",
      "\n",
      "    accuracy                           0.93     50319\n",
      "   macro avg       0.70      0.47      0.49     50319\n",
      "weighted avg       0.92      0.93      0.90     50319\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = classification_report(pred_id[1],pred_id[2])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb3b8a6-6b99-45d6-8648-46f973b8944f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
